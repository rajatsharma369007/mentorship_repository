{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Leakage Test\n",
    "\n",
    "In this notebook, we are testing the effect of data leakage on the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "def tokenize(text):\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "    df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "    X = df.text.values\n",
    "    y = df.category.values\n",
    "    return X, y\n",
    "\n",
    "def display_results(cv, y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Predicted Labels:\", labels)\n",
    "    print(\"True Labels:\", np.unique(y_test))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining two pipeline structure for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_without_transformers():\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def pipeline_with_transformers():\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1610,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the pipeline with transformers outside the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating all the transformer objects\n",
    "countvectorizer = CountVectorizer(tokenizer=tokenize)\n",
    "tfidftransfomer = TfidfTransformer()\n",
    "stdscaler = StandardScaler(with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the transformer objects with training data\n",
    "X_train_countvectorizer = countvectorizer.fit_transform(X_train)\n",
    "X_train_tfidftransfomer = tfidftransfomer.fit_transform(X_train_countvectorizer)\n",
    "X_train_stdscaler = stdscaler.fit_transform(X_train_tfidftransfomer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the transformer objects with testing data\n",
    "X_test_countvectorizer = countvectorizer.transform(X_test)\n",
    "X_test_tfidftransfomer = tfidftransfomer.transform(X_test_countvectorizer)\n",
    "X_test_stdscaler = stdscaler.transform(X_test_tfidftransfomer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9259259259259259, total=   0.9s\n",
      "[CV] clf__n_estimators=100 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. clf__n_estimators=100, score=0.9320987654320988, total=   0.9s\n",
      "[CV] clf__n_estimators=100 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... clf__n_estimators=100, score=0.937888198757764, total=   0.9s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9192546583850931, total=   0.9s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9130434782608695, total=   0.9s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9254658385093167, total=   0.9s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9130434782608695, total=   0.9s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9254658385093167, total=   0.9s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9316770186335404, total=   1.0s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.8930817610062893, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__n_estimators': [100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating the pipeline without transformers and cross-validating it on the training set\n",
    "model_without = pipeline_without_transformers()\n",
    "\n",
    "parameters = {'clf__n_estimators': [100]}\n",
    "\n",
    "cv_without = GridSearchCV(model_without, parameters, cv=10, verbose=3)\n",
    "cv_without.fit(X_train_stdscaler, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_without.score(X_train_stdscaler, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the pipeline with transformers outside the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94073139974779318"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_without.score(X_test_stdscaler, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the pipeline with transformers inside the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9197530864197531, total=   1.3s\n",
      "[CV] clf__n_estimators=100 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. clf__n_estimators=100, score=0.9567901234567902, total=   1.2s\n",
      "[CV] clf__n_estimators=100 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. clf__n_estimators=100, score=0.9565217391304348, total=   1.2s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] ... clf__n_estimators=100, score=0.937888198757764, total=   1.2s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9192546583850931, total=   1.2s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9316770186335404, total=   1.2s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9316770186335404, total=   1.2s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9130434782608695, total=   1.2s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] ... clf__n_estimators=100, score=0.937888198757764, total=   1.2s\n",
      "[CV] clf__n_estimators=100 ...........................................\n",
      "[CV] .. clf__n_estimators=100, score=0.9182389937106918, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...stimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__n_estimators': [100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating the pipeline with transformers\n",
    "model_with = pipeline_with_transformers()\n",
    "\n",
    "parameters = {'clf__n_estimators': [100]}\n",
    "\n",
    "cv_with = GridSearchCV(model_with, parameters, cv=10, verbose=3)\n",
    "cv_with.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_with.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the pipeline with transformers inside the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94073139974779318"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_with.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't find any significant change in the testing scores. They are exactly the same. This might be due to low samples in the dataset. Only 1610 samples in the training and 793 samples in the testing set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
